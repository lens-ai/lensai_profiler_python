{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8LlmZJSpvaWa"
      },
      "outputs": [],
      "source": [
        "pip install lensai-profiler"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import multiprocessing as mp\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.datasets as datasets\n",
        "from lensai_profiler import Metrics\n",
        "from lensai_profiler.sketches import Sketches\n",
        "import os\n",
        "\n",
        "# Set multiprocessing start method\n",
        "mp.set_start_method('spawn', force=True)\n",
        "\n",
        "# Path setup (equivalent to TensorFlow code)\n",
        "URL = 'https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip'\n",
        "path_to_zip = tf.keras.utils.get_file('cats_and_dogs.zip', origin=URL, extract=True)\n",
        "PATH = os.path.join(os.path.dirname(path_to_zip), 'cats_and_dogs_filtered')\n",
        "\n",
        "train_dir = os.path.join(PATH, 'train')\n",
        "validation_dir = os.path.join(PATH, 'validation')\n",
        "\n",
        "# Image transformation and dataset setup\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((160, 160)),\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "train_dataset = datasets.ImageFolder(train_dir, transform=transform)\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=0)  # Set num_workers to 0 to avoid threading issues\n",
        "\n",
        "# Initialize Metrics and Sketches classes\n",
        "metrics = Metrics(framework=\"pt\")\n",
        "sketches = Sketches()\n",
        "\n",
        "num_channels = 3  # Assuming RGB images\n",
        "sketches.register_metric('brightness')\n",
        "sketches.register_metric('sharpness')\n",
        "sketches.register_metric('snr')\n",
        "sketches.register_metric('channel_mean', num_channels=3)\n",
        "sketches.register_metric('channel_histogram', num_channels=3)\n",
        "\n",
        "# Process the dataset and update the KLL sketches\n",
        "for images, labels in train_loader:\n",
        "    images = images.to('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    brightness, sharpness, channel_mean, snr, channel_pixels = metrics.process_batch(images)\n",
        "\n",
        "    sketches.update_sketches(\n",
        "        brightness=brightness.cpu(),\n",
        "        sharpness=sharpness.cpu(),\n",
        "        channel_mean=channel_mean.cpu(),\n",
        "        snr=snr.cpu(),\n",
        "        channel_histogram=channel_pixels.cpu()\n",
        "    )\n",
        "\n",
        "# Save the KLL sketches to a specified directory\n",
        "save_path = '/content/'\n",
        "sketches.save_sketches(save_path)\n"
      ],
      "metadata": {
        "id": "-p8niH-pwJ6V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from lensai_profiler import Metrics, calculate_percentiles\n",
        "from lensai_profiler.sketches import Sketches\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "_URL = 'https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip'\n",
        "path_to_zip = tf.keras.utils.get_file('cats_and_dogs.zip', origin=_URL, extract=True)\n",
        "PATH = os.path.join(os.path.dirname(path_to_zip), 'cats_and_dogs_filtered')\n",
        "\n",
        "train_dir = os.path.join(PATH, 'train')\n",
        "validation_dir = os.path.join(PATH, 'validation')\n",
        "\n",
        "BATCH_SIZE = 32\n",
        "IMG_SIZE = (160, 160)\n",
        "\n",
        "train_dataset = tf.keras.utils.image_dataset_from_directory(train_dir,\n",
        "                                                            shuffle=True,\n",
        "                                                            batch_size=BATCH_SIZE,\n",
        "                                                            image_size=IMG_SIZE)\n",
        "\n",
        "metrics = Metrics(framework=\"tf\")\n",
        "\n",
        "# Initialize Sketches class\n",
        "num_channels = 3  # Assuming RGB images\n",
        "sketches = Sketches()\n",
        "\n",
        "sketches.register_metric('brightness')\n",
        "sketches.register_metric('sharpness')\n",
        "sketches.register_metric('snr')\n",
        "\n",
        "sketches.register_metric('channel_mean', num_channels=3)\n",
        "sketches.register_metric('channel_histogram', num_channels=3)\n",
        "\n",
        "\n",
        "# Process a batch of images in parallel\n",
        "train_dataset = train_dataset.map(lambda images, labels: metrics.process_batch(images), num_parallel_calls=tf.data.AUTOTUNE)\n",
        "\n",
        "# Iterate through the dataset and update the KLL sketches in parallel\n",
        "for batch in train_dataset:\n",
        "    brightness, sharpness, channel_mean, snr, channel_pixels = batch\n",
        "    sketches.update_sketches(\n",
        "        brightness=brightness,\n",
        "        sharpness=sharpness,\n",
        "        channel_mean=channel_mean,\n",
        "        snr=snr,\n",
        "        channel_histogram=channel_pixels\n",
        "    )\n",
        "\n",
        "# Save the KLL sketches to a specified directory\n",
        "save_path = '/content/sample_data/'\n",
        "sketches.save_sketches(save_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vtiQKJ-jirBa",
        "outputId": "57c2a051-6352-4a2f-82af-be1b1fc75b7d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 2000 files belonging to 2 classes.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.10/dist-packages/tensorflow/python/util/deprecation.py:660: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use fn_output_signature instead\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "t-l-qk5-QEa7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}